import math
import os
from collections import namedtuple

# ==========================================
# Configuration
# ==========================================
inst_dir = "magi_attention/csrc/comm/grpcoll/instantiations"
os.makedirs(inst_dir, exist_ok=True)

# Batch size controls the number of template instantiations per .cu file.
BATCH_SIZE = 12


# ==========================================
# C++ Argument Signatures (Constants)
# ==========================================
# Extracting these long strings prevents linting errors and improves readability.

INTRANODE_CAST_ARGS = """    void* recv_x,
    float* recv_lse,
    const void* x,
    const float* lse,
    void* recv_x_2nd,
    const void* x_2nd,
    void* recv_x_3rd,
    const void* x_3rd,
    int* recv_src_idx,
    int* recv_channel_offset,
    int* send_head,
    const bool* is_token_in_rank,
    const int* channel_prefix_matrix,
    const int64_t* post_perm_idx,
    int num_tokens,
    int hidden_int4,
    int num_heads,
    void** buffer_ptrs,
    int rank,
    cudaStream_t stream,
    int num_sms,
    int num_max_send_tokens,
    int num_recv_buffer_tokens,
    std::optional<magi_attn_ext::KernelBarrier>& kernel_barrier"""

INTRANODE_REDUCE_ARGS = """    void* reduced_x,
    float* reduced_lse,
    const void* x,
    const float* lse,
    void* reduced_x_2nd,
    const void* x_2nd,
    int* send_head,
    const int* src_idx,
    const int* rank_prefix_matrix,
    const int* channel_prefix_matrix,
    const int64_t* pre_perm_idx,
    int num_reduced_tokens,
    int hidden_size,
    int num_heads,
    void** buffer_ptrs,
    int rank,
    cudaStream_t stream,
    int num_sms,
    int num_max_send_tokens,
    int num_recv_buffer_tokens,
    ReduceOp reduce_op,
    std::optional<magi_attn_ext::KernelBarrier>& kernel_barrier"""

INTERNODE_CAST_ARGS = """    void* recv_x,
    float* recv_lse,
    const void* x,
    const float* lse,
    void* recv_x_2nd,
    const void* x_2nd,
    void* recv_x_3rd,
    const void* x_3rd,
    void* recv_src_meta,
    int* send_rdma_head,
    int* send_nvl_head,
    int* recv_rdma_channel_prefix_matrix,
    int* recv_gbl_channel_prefix_matrix,
    const int* rdma_channel_prefix_matrix,
    const int* recv_rdma_rank_prefix_sum,
    const int* gbl_channel_prefix_matrix,
    const int* recv_gbl_rank_prefix_sum,
    const bool* is_token_in_rank,
    const int64_t* post_perm_idx,
    int num_tokens,
    int hidden_int4,
    int num_heads,
    void* rdma_buffer_ptr,
    int num_max_rdma_chunked_send_tokens,
    int num_max_rdma_chunked_recv_tokens,
    void** buffer_ptrs,
    int num_max_nvl_chunked_send_tokens,
    int num_max_nvl_chunked_recv_tokens,
    int rank,
    int num_ranks,
    int num_channels,
    bool is_cached_group_cast,
    cudaStream_t stream,
    std::optional<magi_attn_ext::KernelBarrier>& kernel_barrier"""

INTERNODE_REDUCE_ARGS = """    void* reduced_x,
    float* reduced_lse,
    const void* x,
    const float* lse,
    void* reduced_x_2nd,
    const void* x_2nd,
    const bool* is_reduced_token_in_rank,
    const int* reduced_rdma_head,
    const int* reduced_nvl_head,
    const void* src_meta,
    const int* rdma_channel_prefix_matrix,
    const int* rdma_rank_prefix_sum,
    const int* gbl_channel_prefix_matrix,
    const int* gbl_rank_prefix_sum,
    const int64_t* pre_perm_idx,
    int num_reduced_tokens,
    int hidden_size,
    int num_heads,
    void* rdma_buffer_ptr,
    int num_max_rdma_chunked_send_tokens,
    int num_max_rdma_chunked_recv_tokens,
    void** buffer_ptrs,
    int num_max_nvl_chunked_send_tokens,
    int num_max_nvl_chunked_recv_tokens,
    int rank,
    int num_ranks,
    cudaStream_t stream,
    int num_channels,
    std::optional<magi_attn_ext::KernelBarrier>& kernel_barrier,
    bool acc_reduce,
    ReduceOp reduce_op"""


# ==========================================
# Helper Functions
# ==========================================


def write_batched_file(category_name, file_index, headers, namespace, content_list):
    """Generates a single .cu file containing a batch of instantiations."""
    if not content_list:
        return

    filename = f"{category_name}_part{file_index}.cu"
    filepath = os.path.join(inst_dir, filename)

    print(f"Generating {filepath} ({len(content_list)} instantiations)...")

    with open(filepath, "w") as f:
        # File Header
        f.write(
            "/**********************************************************************************\n"
        )
        f.write(" * Copyright (c) 2025-2026 SandAI. All Rights Reserved.\n")
        f.write(" * Auto-generated by generate_inst.py (Batched Version)\n")
        f.write(
            " *********************************************************************************/\n\n"
        )

        # Includes
        for h in headers:
            f.write(f'#include "{h}"\n')
        f.write("\n")

        # Namespace Start
        f.write(f"namespace {namespace} {{\n\n")

        # Instantiations
        for content in content_list:
            f.write(content)
            f.write("\n")

        # Namespace End
        f.write(f"}} // namespace {namespace}\n")


def process_batch(category_name, headers, namespace, all_instantiations):
    """Splits collected instantiations into batches and writes them to files."""
    total_inst = len(all_instantiations)
    num_files = math.ceil(total_inst / BATCH_SIZE)

    for i in range(num_files):
        start_idx = i * BATCH_SIZE
        end_idx = min((i + 1) * BATCH_SIZE, total_inst)
        batch_content = all_instantiations[start_idx:end_idx]

        write_batched_file(category_name, i, headers, namespace, batch_content)


# ==========================================
# 1. Intranode Group Cast
# ==========================================

intranode_cast_ranks_warps = [
    (1, 24),
    (2, 24),
    (3, 24),
    (4, 24),
    (5, 20),
    (6, 24),
    (7, 21),
    (8, 24),
]
intranode_cast_data_groups = [1, 2, 3]

inst_list = []
for data_groups in intranode_cast_data_groups:
    for ranks, warps in intranode_cast_ranks_warps:
        tpl_sig = f"template void launch_group_cast<{data_groups}, {ranks}, {warps}>"
        inst_list.append(f"{tpl_sig}(\n{INTRANODE_CAST_ARGS}\n);")

process_batch(
    "intranode_cast",
    ["kernels/intranode.cuh"],
    "magi_attn_comm::grpcoll::intranode",
    inst_list,
)

# ==========================================
# 2. Intranode Group Reduce
# ==========================================

DtypeConfig = namedtuple(
    "DtypeConfig", ["dtype", "comm_dtype", "reduce_dtype", "suffix"]
)
dtypes = [
    DtypeConfig("nv_bfloat16", "nv_bfloat16", "float", "bf16"),
    DtypeConfig("half", "half", "float", "fp16"),
    DtypeConfig("float", "nv_bfloat16", "float", "fp32_bf16"),
    DtypeConfig("float", "half", "float", "fp32_fp16"),
    DtypeConfig("float", "float", "float", "fp32"),
    DtypeConfig("double", "double", "double", "fp64"),
]

intranode_reduce_ranks_warps = intranode_cast_ranks_warps
intranode_reduce_data_groups = [1, 2]
reduce_acc = [True, False]

inst_list = []
for dconfig in dtypes:
    for data_groups in intranode_reduce_data_groups:
        for ranks, warps in intranode_reduce_ranks_warps:
            for acc in reduce_acc:
                acc_str = "true" if acc else "false"
                tpl_sig = f"template void launch_group_reduce<{dconfig.dtype}, {dconfig.comm_dtype}, {dconfig.reduce_dtype}, {data_groups}, {ranks}, {warps}, {acc_str}>"  # noqa: E501
                inst_list.append(f"{tpl_sig}(\n{INTRANODE_REDUCE_ARGS}\n);")

process_batch(
    "intranode_reduce",
    ["kernels/intranode.cuh"],
    "magi_attn_comm::grpcoll::intranode",
    inst_list,
)

# ==========================================
# 3. Internode Group Cast
# ==========================================

internode_cast_rdma_ranks = [2, 4, 8, 16, 32]
internode_cast_data_groups = [1, 2, 3]

inst_list = []
for data_groups in internode_cast_data_groups:
    for rdma_ranks in internode_cast_rdma_ranks:
        tpl_sig = f"template void launch_group_cast<{data_groups}, {rdma_ranks}>"
        inst_list.append(f"{tpl_sig}(\n{INTERNODE_CAST_ARGS}\n);")

process_batch(
    "internode_cast",
    ["kernels/internode.cuh"],
    "magi_attn_comm::grpcoll::internode",
    inst_list,
)

# ==========================================
# 4. Internode Group Reduce
# ==========================================

internode_reduce_ranks_warps = [(2, 24), (4, 24), (8, 24), (16, 24), (32, 32)]
internode_reduce_data_groups = [1, 2]


def get_internode_reduce_configs(warps, reduce_dtype):
    """Determine head configurations and TMA stages based on warps and dtype."""
    configs = []
    # Config A: Small Head count
    heads_a = 48
    tma_a = 1 if warps > 24 else 2
    configs.append((heads_a, tma_a))

    # Config B: Large Head count (depends on precision)
    tma_b = 1
    if reduce_dtype == "double":
        heads_b = 86 if warps > 24 else 120
    else:
        heads_b = 128
    configs.append((heads_b, tma_b))

    return configs


inst_list = []
for dconfig in dtypes:
    for data_groups in internode_reduce_data_groups:
        for rdma_ranks, fwd_warps in internode_reduce_ranks_warps:
            valid_configs = get_internode_reduce_configs(
                fwd_warps, dconfig.reduce_dtype
            )

            for kMaxNumHeads, kNumTMAStages in valid_configs:
                tpl_sig = f"template void launch_group_reduce<{dconfig.dtype}, {dconfig.comm_dtype}, {dconfig.reduce_dtype}, {data_groups}, {rdma_ranks}, {kMaxNumHeads}, {fwd_warps}, {kNumTMAStages}>"  # noqa: E501
                inst_list.append(f"{tpl_sig}(\n{INTERNODE_REDUCE_ARGS}\n);")

process_batch(
    "internode_reduce",
    ["kernels/internode.cuh"],
    "magi_attn_comm::grpcoll::internode",
    inst_list,
)

print("Done generating batched files.")
